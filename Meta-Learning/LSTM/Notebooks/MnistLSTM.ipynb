{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MnistLSTM.ipynb","provenance":[],"authorship_tag":"ABX9TyOArLKKi90erl7otbF6tRbN"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"aC8jT8PK8jmw","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","import numpy as np\n","from tensorflow.keras import Model, layers\n","from __future__ import absolute_import,print_function,division"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XKleCX03--4D","colab_type":"code","colab":{}},"source":["#Mnist parameters\n","num_classes = 10\n","num_features = 784\n","\n","#Training Params\n","learning_rate = 0.001\n","training_steps = 2000\n","batch_size = 16\n","display_step = 100\n","\n","#Network Paramters\n","# MNIST image shape is 28*28px, we will then handle 28 sequences of 28 timesteps for every sample.\n","num_input = 28 # number of sequences.\n","timesteps = 28 # timesteps.\n","num_units = 64 # number of neurons for the LSTM layer."],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"76aht-U7AaSG","colab_type":"code","colab":{}},"source":["from tensorflow.keras.datasets import mnist\n","(x_train, y_train), (x_test, y_test) = mnist.load_data()\n","\n","x_train, x_test = np.array(x_train, np.float32), np.array(x_test, np.float32)\n","x_train = x_train.reshape([-1, 28, 28])\n","x_test = x_test.reshape([-1, num_features])\n","\n","x_train, x_test = x_train/255. , x_test/255."],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xHrjLJwvBGrw","colab_type":"code","colab":{}},"source":["train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n","train_data = train_data.repeat().shuffle(5000).batch(batch_size).prefetch(1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"t6TsqjC9Br9C","colab_type":"code","colab":{}},"source":["class LSTM(Model):\n","  #set layers\n","  def __init__(self):\n","    super(LSTM, self).__init__()\n","    #RNN (LSTM) hidden layer\n","    self.lstm_layer = layers.LSTM(units=num_classes)\n","    self.out = layers.Dense(num_classes)\n","\n","  #set forward pass\n","  def call(self, x, is_trainable=False):\n","    #LSTM layer\n","    x = self.lstm_layer(x)\n","    #output layers \n","    x = self.out(x)\n","\n","    if not is_trainable:\n","      x = tf.nn.softmax(x)\n","\n","    return x\n","\n","lstm_net = LSTM()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"J3PlamIUDpOh","colab_type":"code","colab":{}},"source":["def cross_entropy_loss(x, y):\n","  y = tf.cast(y, tf.int64)\n","\n","  loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels = y, logits=x)\n","\n","  return tf.reduce_mean(loss)\n","\n","def accuracy(y_pred, y_true):\n","  correct_prediction = tf.equal(tf.argmax(y_pred, 1), tf.cast(y_true, tf.int64))\n","  return tf.reduce_mean(tf.cast(correct_prediction, tf.float32), axis=-1)\n","\n","optimizer = tf.optimizers.Adam(learning_rate)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Rlyk_8daFeYm","colab_type":"code","colab":{}},"source":["def run_optimization(x, y):\n","\n","  with tf.GradientTape() as g:\n","\n","    pred = lstm_net(x, is_trainable=True)\n","    loss = cross_entropy_loss(pred, y)\n","\n","  gradients = g.gradient(loss, lstm_net.trainable_variables)\n","  optimizer.apply_gradients(zip(gradients, lstm_net.trainable_variables))\n","\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y2Ez7O6vHTPa","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":377},"outputId":"db9a5557-1b2a-4bd4-f41e-f708fd436d68","executionInfo":{"status":"ok","timestamp":1589308509993,"user_tz":-330,"elapsed":78330,"user":{"displayName":"Mohit Kulkarni","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh2Gg-miY6SQAbi9NY7LkKb0VPcjtn4bsjkYTYaEw=s64","userId":"09495840121407317655"}}},"source":["for step, (batch_x, batch_y) in enumerate(train_data.take(training_steps), 1):\n","\n","  run_optimization(batch_x, batch_y)\n","\n","  if step % display_step == 0:\n","    pred = lstm_net(batch_x, is_trainable = True)\n","    loss = cross_entropy_loss(pred, batch_y)\n","    acc = accuracy(pred, batch_y)\n","    print(\"step: %i, loss: %f, accuracy: %f\" %(step, loss, acc))"],"execution_count":49,"outputs":[{"output_type":"stream","text":["step: 100, loss: 2.280466, accuracy: 0.250000\n","step: 200, loss: 2.287636, accuracy: 0.062500\n","step: 300, loss: 2.042763, accuracy: 0.375000\n","step: 400, loss: 1.809712, accuracy: 0.375000\n","step: 500, loss: 1.716209, accuracy: 0.500000\n","step: 600, loss: 1.784284, accuracy: 0.375000\n","step: 700, loss: 1.107306, accuracy: 0.562500\n","step: 800, loss: 1.409682, accuracy: 0.375000\n","step: 900, loss: 1.433112, accuracy: 0.562500\n","step: 1000, loss: 1.285776, accuracy: 0.562500\n","step: 1100, loss: 1.040275, accuracy: 0.687500\n","step: 1200, loss: 1.198076, accuracy: 0.687500\n","step: 1300, loss: 0.670228, accuracy: 0.937500\n","step: 1400, loss: 1.424047, accuracy: 0.625000\n","step: 1500, loss: 1.398649, accuracy: 0.437500\n","step: 1600, loss: 1.353969, accuracy: 0.437500\n","step: 1700, loss: 0.832241, accuracy: 0.750000\n","step: 1800, loss: 0.761235, accuracy: 0.812500\n","step: 1900, loss: 0.929557, accuracy: 0.687500\n","step: 2000, loss: 0.727454, accuracy: 0.875000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_rq_L6eSIXzx","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}